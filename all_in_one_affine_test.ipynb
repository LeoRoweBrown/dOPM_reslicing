{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from tifffile import imwrite, imread, tiffcomment, TiffFile\n",
    "from ome_types import from_tiff\n",
    "from glob import glob\n",
    "import os\n",
    "import affine_matrices as affine\n",
    "from scipy.ndimage import affine_transform\n",
    "from timeit import default_timer as timer\n",
    "from npy2bdv import BdvWriter\n",
    "from napari import Viewer\n",
    "import lxml\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view1', 'E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view2']\n",
      "E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\dOPM_t0000_p0000_z0000_c0000_view1\n",
      "E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\dOPM_t0000_p0000_z0000_c0000_view2\n",
      "{'p0000': ['E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view1', 'E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view2']}\n",
      "{'p0000': [{'time': '0000', 'z': '0000', 'channel': '0000', 'dir': 'E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view1', 'angle': -45}, {'time': '0000', 'z': '0000', 'channel': '0000', 'dir': 'E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view2', 'angle': 45}]}\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# root_dir = \"A:/leo/micromanager/bonemarrow/data/\"\n",
    "# root_dir = \"A:/leo/micromanager/dan/D_and_E/data/\"\n",
    "# root_dir = \"A:/leo/micromanager/dan/D_and_E_frome4/data/\"\n",
    "root_dir = \"E:/dopm_reslicing/\"\n",
    "\n",
    "# tiff_data_dir = os.path.join(root_dir, \"y_stage_scan_20241216-171205_c0p0/\")\n",
    "tiff_data_dir = os.path.join(root_dir, \"y_stage_scan_20241216-171205_c0p0\")\n",
    "# tiff_data_dir = os.path.join(root_dir, \"y_stage_scan_20241209-144142\")\n",
    "# tiff_data_dir = os.path.join(root_dir, \"y_stage_scan_20250116-160803\")\n",
    "# tiff_data_dir = os.path.join(root_dir, \"y_stage_scan_20250116-172759\")\n",
    "\n",
    "folder_name = \"HamamatsuHam_DCAM-dopm\"\n",
    "\n",
    "OPM_ANGLE = 45  # opm angle in degrees\n",
    "\n",
    "tiff_dirs = glob(os.path.join(tiff_data_dir, \"dOPM*\"))  # unique dirs for each MDA dimension e.g. channel, time, z\n",
    "print(tiff_dirs)\n",
    "\n",
    "# what to do with z slices\n",
    "only_keep_z0 = True\n",
    "\n",
    "# group dirs with the same position pattern i.e. p0000, p0001, p0002\n",
    "grouped_dirs = {}\n",
    "grouped_details = {}\n",
    "\n",
    "for tiff_dir in tiff_dirs:\n",
    "    print(tiff_dir)\n",
    "    view_details = os.path.basename(tiff_dir).split(\"_\")\n",
    "    angle = -OPM_ANGLE if \"view1\" in view_details[-1] else OPM_ANGLE\n",
    "    position_key = view_details[2]\n",
    "    position_str = position_key[1:]  # remove 'p' from 'p0000'\n",
    "    time_str = view_details[1][1:]  # remove 't' from 't0000'\n",
    "    z_str = view_details[3][1:]  # remove 'z' from 'z0000'\n",
    "    channel_str = view_details[4][1:]  # remove 'c' from 'c0000'\n",
    "\n",
    "    tiff_dir_dict = {}\n",
    "    tiff_dir_dict[\"time\"] = time_str\n",
    "    tiff_dir_dict[\"z\"] = z_str\n",
    "    tiff_dir_dict[\"channel\"] = channel_str\n",
    "    tiff_dir_dict[\"dir\"] = tiff_dir\n",
    "    tiff_dir_dict[\"angle\"] = angle\n",
    "\n",
    "    if only_keep_z0 and int(z_str)>0:\n",
    "        continue\n",
    "\n",
    "    if position_key in grouped_dirs:\n",
    "        grouped_dirs[position_key].append(tiff_dir)\n",
    "        grouped_details[position_key].append(tiff_dir_dict)\n",
    "    else:\n",
    "        grouped_dirs[position_key] = [tiff_dir]\n",
    "        grouped_details[position_key] = [tiff_dir_dict]\n",
    "    \n",
    "print(grouped_dirs)\n",
    "print(grouped_details)\n",
    "# unique_positions = list(grouped_dirs.keys())\n",
    "\n",
    "for p, d in grouped_details.items():\n",
    "    # number of channels in position (extract only 'channel' item from each dict)\n",
    "    channels = list(set([int(i[\"channel\"]) for i in d]))\n",
    "    # do previous line in a neater way\n",
    "    \n",
    "\n",
    "    print(channels)\n",
    "\n",
    "# now do the same thing for time and z\n",
    "# then iterate over all combinations of positions, times and z to get the full list of files to process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250124-122939\n",
      "channels ['0000', '0000'] time ['0000', '0000'] z ['0000', '0000'] angle [0, 90]\n",
      "n_channels 1 n_times 1 n_z 1 n_angles 2\n",
      "E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\dOPM_t0000_p0000_z0000_c0000_view1\n",
      "angle -45\n",
      "position p0000\n",
      "time 0000\n",
      "z 0000\n",
      "channel 0000\n",
      "E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\dOPM_t0000_p0000_z0000_c0000_view1\\HamamatsuHam_DCAM-dopm/*.tif\n",
      "tifs in dir ['E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view1\\\\HamamatsuHam_DCAM-dopm\\\\HamamatsuHam_DCAM-dopm_MMStack.ome.tif', 'E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view1\\\\HamamatsuHam_DCAM-dopm\\\\HamamatsuHam_DCAM-dopm_MMStack_1.ome.tif', 'E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view1\\\\HamamatsuHam_DCAM-dopm\\\\HamamatsuHam_DCAM-dopm_MMStack_2.ome.tif', 'E:/dopm_reslicing/y_stage_scan_20241216-171205_c0p0\\\\dOPM_t0000_p0000_z0000_c0000_view1\\\\HamamatsuHam_DCAM-dopm\\\\HamamatsuHam_DCAM-dopm_MMStack_3.ome.tif']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtifs in dir\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacks)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# get ome metadata using ome-types library, tifffile doesnt parse xml into a dict unlike mm metadata\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m omexml \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_tiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m iminfo \u001b[38;5;241m=\u001b[39m omexml\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     83\u001b[0m size_x \u001b[38;5;241m=\u001b[39m iminfo\u001b[38;5;241m.\u001b[39mpixels\u001b[38;5;241m.\u001b[39msize_x\n",
      "File \u001b[1;32mc:\\Users\\lnr19\\Anaconda3\\envs\\dopm_bdv\\Lib\\site-packages\\ome_types\\_conversion.py:158\u001b[0m, in \u001b[0;36mfrom_tiff\u001b[1;34m(path, validate, parser_kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_tiff\u001b[39m(\n\u001b[0;32m    139\u001b[0m     path: Path \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m BinaryIO,\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    141\u001b[0m     validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m     parser_kwargs: ParserKwargs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OME:\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate an OME object from a TIFF file.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m        will be used.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     xml \u001b[38;5;241m=\u001b[39m \u001b[43mtiff2xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_xml(xml, validate\u001b[38;5;241m=\u001b[39mvalidate, parser_kwargs\u001b[38;5;241m=\u001b[39mparser_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\lnr19\\Anaconda3\\envs\\dopm_bdv\\Lib\\site-packages\\ome_types\\_conversion.py:206\u001b[0m, in \u001b[0;36mtiff2xml\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo OME metadata found in file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdesc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    207\u001b[0m     desc \u001b[38;5;241m=\u001b[39m desc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range"
     ]
    }
   ],
   "source": [
    "# get current date for file timestamp\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(date_time)\n",
    "\n",
    "out_dir = os.path.join(root_dir, f\"deskewed_{date_time}/\")\n",
    "\n",
    "if os.path.exists(out_dir):\n",
    "    print(\"Output directory already exists, exiting\")\n",
    "    raise(FileExistsError)\n",
    "\n",
    "# npos to do\n",
    "stop_early = False\n",
    "npos_max = 5\n",
    "\n",
    "i_p = 0\n",
    "# loop over grouped dirs to debug\n",
    "for position, details in grouped_details.items():\n",
    "    if stop_early and i_p>npos_max:\n",
    "        break\n",
    "    i_p+=1\n",
    "    dirs = [d[\"dir\"] for d in details]\n",
    "    channels_strs = [d[\"channel\"] for d in details]\n",
    "    time_strs = [d[\"time\"] for d in details]\n",
    "    z_strs = [d[\"z\"] for d in details]\n",
    "    angles = [d[\"angle\"] + OPM_ANGLE for d in details]\n",
    "    angle_idxc = [0 if a == 0 else 1 for a in angles]\n",
    "\n",
    "    # print all those dimenisons e.g. time, z, channel in a single print statement\n",
    "    print(\"channels\", channels_strs, \"time\", time_strs, \"z\", z_strs, \"angle\", angles)\n",
    "\n",
    "    # to get n channels etc. use set(channels) etc. to get unique values\n",
    "    n_channels = len(set(channels_strs))\n",
    "    n_times = len(set(time_str))\n",
    "    n_z = len(set(z_str)) # if not only_keep_z0 else 1\n",
    "    n_angles = len(set(angles))\n",
    "\n",
    "    print(\"n_channels\", n_channels, \"n_times\", n_times, \"n_z\", n_z, \"n_angles\", n_angles)\n",
    "\n",
    "    # for BDV dataset attributes\n",
    "    channel_attr = [None]*n_channels\n",
    "    angle_attr = [None]*n_angles\n",
    "\n",
    "    # create BDV dataset\n",
    "    save_path = os.path.join(out_dir, \"pos_\"+position)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_file = os.path.join(save_path, \"dataset.h5\")\n",
    "\n",
    "    bdv_writer = BdvWriter(save_file, \n",
    "                           nchannels=n_channels, \n",
    "                           nilluminations=1, \n",
    "                           nangles=n_angles,\n",
    "                           ntiles= n_z)\n",
    "\n",
    "    for n, tiff_dir in enumerate(dirs):\n",
    "        print(tiff_dir)\n",
    "        view_details = os.path.basename(tiff_dir).split(\"_\")\n",
    "        angle = -OPM_ANGLE if \"view1\" in view_details[-1] else OPM_ANGLE\n",
    "        angle_i = angle_idxc[n]\n",
    "        position_str = position\n",
    "        position_i = int(position_str[1:])\n",
    "        time_str = time_strs[n]\n",
    "        time_i = int(time_str)\n",
    "        z_str = z_strs[n]\n",
    "        z_i = int(z_str)\n",
    "        channel_str = channels_strs[n]\n",
    "        channel_i = int(channel_str)\n",
    "\n",
    "        print(\"angle\", angle)\n",
    "        print(\"position\", position_str)\n",
    "        print(\"time\", time_str)\n",
    "        print(\"z\", z_str)\n",
    "        print(\"channel\", channel_str)\n",
    "\n",
    "        # print(stack_dir)\n",
    "        print(os.path.join(tiff_dir, \"HamamatsuHam_DCAM-dopm/*.tif\"))\n",
    "        stacks = glob(os.path.join(tiff_dir, \"HamamatsuHam_DCAM-dopm/*.tif\"))\n",
    "        print(\"tifs in dir\", stacks)\n",
    "        print(\"reading ome of first tif\", stacks[0])\n",
    "        # get ome metadata using ome-types library, tifffile doesnt parse xml into a dict unlike mm metadata\n",
    "        omexml = from_tiff(stacks[0])\n",
    "        iminfo = omexml.images[0]\n",
    "\n",
    "        size_x = iminfo.pixels.size_x\n",
    "        size_y = iminfo.pixels.size_y\n",
    "        size_z = len(omexml.images)\n",
    "        vox_size_x_um = iminfo.pixels.physical_size_x\n",
    "        vox_size_y_um = iminfo.pixels.physical_size_y\n",
    "        vox_size_z_um = iminfo.pixels.physical_size_z\n",
    "        \n",
    "        print(\"size_x\", size_x)\n",
    "        print(\"size_y\", size_y)\n",
    "        print(\"size_z\", size_z)\n",
    "\n",
    "        imstack = np.zeros((size_z, size_y, size_x), dtype=np.uint16)\n",
    "\n",
    "        start_time = timer()\n",
    "\n",
    "        # read the mm-split 4gb tiff stacks into one big stack (matrix), think about memory concerns...\n",
    "        \n",
    "        offset = 0\n",
    "        for i in range(len(stacks)):\n",
    "            print(\"loading\",  stacks[i])\n",
    "            with TiffFile(stacks[i]) as tif:\n",
    "                mm_metadata = tif.micromanager_metadata\n",
    "                for n, page in enumerate(tif.pages):\n",
    "                    # print(\"page\", n)\n",
    "                    imstack[n+offset,:,:] = page.asarray() # expects zyx\n",
    "            offset += n+1\n",
    "\n",
    "        end_time = timer()\n",
    "        print(\"Read time\", (end_time-start_time), \"ms\")\n",
    "\n",
    "        laser_meta = mm_metadata['Summary']['UserData']['laser']\n",
    "        filter_meta = mm_metadata['Summary']['UserData']['filter']\n",
    "        \n",
    "        channel_attr[channel_i] = f\"{laser_meta}\"\n",
    "        angle_attr[angle_i] = f\"{angle}\"\n",
    "\n",
    "        rotation_matrix = affine.rotation_matrix(theta=np.pi/2, axis='x', square=False)\n",
    "        skew_angle = np.pi*(angle-OPM_ANGLE)/180\n",
    "        scale_matrix = affine.scale_matrix(sz=np.sin(skew_angle), square=False)\n",
    "        skew_matrix = affine.skew_matrix(skew_angle, square=False)\n",
    "        total_affine = skew_matrix @ scale_matrix @ rotation_matrix\n",
    "\n",
    "        start_time = timer()  # start timer for saving h5 file\n",
    "\n",
    "        angle_from_zero = angle+OPM_ANGLE\n",
    "        print(\"angle\", angle_i, \"time\",time_i,\"tile\",z_i,\"channel\",channel_i)\n",
    "        bdv_writer.append_view(\n",
    "            imstack, angle=angle_i, time=time_i, tile=z_i, channel=channel_i,\n",
    "            calibration=(vox_size_x_um, vox_size_y_um, vox_size_z_um),\n",
    "            voxel_size_xyz=(vox_size_x_um, vox_size_y_um, vox_size_z_um),\n",
    "            voxel_units='micron',\n",
    "            m_affine=total_affine)\n",
    "        print(f\"dataset in {save_file}\")\n",
    "        bdv_writer.write_xml()\n",
    "        \n",
    "    # \n",
    "    bdv_writer.set_attribute_labels('angle', angle_attr) \n",
    "    bdv_writer.set_attribute_labels('channel', channel_attr)\n",
    "    \"\"\"\n",
    "    bdv_writer.append_affine(\n",
    "        affine.rotation_matrix(theta=np.pi/2, axis='x', square=False),\n",
    "        name_affine='90 deg rotation about x')\n",
    "    skew_angle = -np.pi*(angle)/180\n",
    "    bdv_writer.append_affine(\n",
    "        affine.scale_matrix(sz=np.sin(skew_angle), square=False),\n",
    "        name_affine='scale before shear')\n",
    "    bdv_writer.append_affine(\n",
    "        affine.skew_matrix(skew_angle, square=False),\n",
    "        name_affine='shear to deskew')\n",
    "    bdv_writer.set_attribute_labels('angle', angle_attr) \n",
    "    bdv_writer.set_attribute_labels('channel', channel_attr)\n",
    "    \"\"\"\n",
    "    bdv_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dopm_bdv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
